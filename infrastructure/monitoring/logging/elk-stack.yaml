# Centralized Logging Infrastructure for Financial Standards Compliance
# This configuration deploys Elasticsearch, Logstash, and Kibana (ELK Stack) with security enhancements

apiVersion: v1
kind: Namespace
metadata:
  name: logging
  labels:
    name: logging
    compliance: "pci-dss,gdpr,soc2"
---
# Elasticsearch StatefulSet
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch
  namespace: logging
  labels:
    app: elasticsearch
    component: logging
spec:
  serviceName: elasticsearch
  replicas: 3
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      labels:
        app: elasticsearch
        component: logging
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      initContainers:
      - name: increase-vm-max-map
        image: busybox:1.35
        command: ['sh', '-c', 'sysctl -w vm.max_map_count=262144']
        securityContext:
          privileged: true
      - name: increase-fd-ulimit
        image: busybox:1.35
        command: ['sh', '-c', 'ulimit -n 65536']
        securityContext:
          privileged: true
      containers:
      - name: elasticsearch
        image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
        ports:
        - containerPort: 9200
          name: rest
          protocol: TCP
        - containerPort: 9300
          name: inter-node
          protocol: TCP
        volumeMounts:
        - name: data
          mountPath: /usr/share/elasticsearch/data
        - name: config
          mountPath: /usr/share/elasticsearch/config/elasticsearch.yml
          subPath: elasticsearch.yml
        - name: certs
          mountPath: /usr/share/elasticsearch/config/certs
          readOnly: true
        env:
        - name: cluster.name
          value: fluxora-logging-cluster
        - name: node.name
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: discovery.seed_hosts
          value: "elasticsearch-0.elasticsearch,elasticsearch-1.elasticsearch,elasticsearch-2.elasticsearch"
        - name: cluster.initial_master_nodes
          value: "elasticsearch-0,elasticsearch-1,elasticsearch-2"
        - name: ES_JAVA_OPTS
          value: "-Xms2g -Xmx2g"
        - name: xpack.security.enabled
          value: "true"
        - name: xpack.security.http.ssl.enabled
          value: "true"
        - name: xpack.security.transport.ssl.enabled
          value: "true"
        - name: ELASTIC_PASSWORD
          valueFrom:
            secretKeyRef:
              name: elasticsearch-credentials
              key: password
        resources:
          limits:
            cpu: 2000m
            memory: 4Gi
          requests:
            cpu: 1000m
            memory: 2Gi
        livenessProbe:
          httpGet:
            path: /_cluster/health
            port: 9200
            scheme: HTTPS
          initialDelaySeconds: 90
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /_cluster/health?wait_for_status=yellow&timeout=5s
            port: 9200
            scheme: HTTPS
          initialDelaySeconds: 60
          periodSeconds: 10
      volumes:
      - name: config
        configMap:
          name: elasticsearch-config
      - name: certs
        secret:
          secretName: elasticsearch-certs
  volumeClaimTemplates:
  - metadata:
      name: data
      labels:
        app: elasticsearch
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: "gp3-encrypted"
      resources:
        requests:
          storage: 100Gi
---
# Elasticsearch Service
apiVersion: v1
kind: Service
metadata:
  name: elasticsearch
  namespace: logging
  labels:
    app: elasticsearch
spec:
  clusterIP: None
  selector:
    app: elasticsearch
  ports:
  - port: 9200
    name: rest
  - port: 9300
    name: inter-node
---
# Elasticsearch Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: elasticsearch-config
  namespace: logging
data:
  elasticsearch.yml: |
    cluster.name: fluxora-logging-cluster
    network.host: 0.0.0.0
    
    # Security Configuration
    xpack.security.enabled: true
    xpack.security.http.ssl.enabled: true
    xpack.security.http.ssl.key: certs/elasticsearch.key
    xpack.security.http.ssl.certificate: certs/elasticsearch.crt
    xpack.security.http.ssl.certificate_authorities: certs/ca.crt
    xpack.security.transport.ssl.enabled: true
    xpack.security.transport.ssl.key: certs/elasticsearch.key
    xpack.security.transport.ssl.certificate: certs/elasticsearch.crt
    xpack.security.transport.ssl.certificate_authorities: certs/ca.crt
    
    # Audit Logging for Compliance
    xpack.security.audit.enabled: true
    xpack.security.audit.logfile.events.include:
      - access_denied
      - access_granted
      - anonymous_access_denied
      - authentication_failed
      - authentication_success
      - change_password
      - connection_denied
      - connection_granted
      - tampered_request
      - run_as_denied
      - run_as_granted
    
    # Index Management
    action.auto_create_index: false
    action.destructive_requires_name: true
    
    # Memory and Performance
    bootstrap.memory_lock: true
    indices.memory.index_buffer_size: 20%
    
    # Data Retention (90 days for compliance)
    cluster.routing.allocation.disk.watermark.low: 85%
    cluster.routing.allocation.disk.watermark.high: 90%
    cluster.routing.allocation.disk.watermark.flood_stage: 95%
---
# Logstash Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: logstash
  namespace: logging
  labels:
    app: logstash
    component: logging
spec:
  replicas: 2
  selector:
    matchLabels:
      app: logstash
  template:
    metadata:
      labels:
        app: logstash
        component: logging
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
      - name: logstash
        image: docker.elastic.co/logstash/logstash:8.11.0
        ports:
        - containerPort: 5044
          name: beats
        - containerPort: 9600
          name: http
        volumeMounts:
        - name: config
          mountPath: /usr/share/logstash/config/logstash.yml
          subPath: logstash.yml
        - name: pipeline
          mountPath: /usr/share/logstash/pipeline
        - name: patterns
          mountPath: /usr/share/logstash/patterns
        - name: certs
          mountPath: /usr/share/logstash/config/certs
          readOnly: true
        env:
        - name: LS_JAVA_OPTS
          value: "-Xmx2g -Xms2g"
        - name: ELASTICSEARCH_HOSTS
          value: "https://elasticsearch:9200"
        - name: ELASTICSEARCH_USERNAME
          value: "logstash_writer"
        - name: ELASTICSEARCH_PASSWORD
          valueFrom:
            secretKeyRef:
              name: elasticsearch-credentials
              key: logstash_password
        resources:
          limits:
            cpu: 2000m
            memory: 4Gi
          requests:
            cpu: 1000m
            memory: 2Gi
        livenessProbe:
          httpGet:
            path: /
            port: 9600
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /
            port: 9600
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: config
        configMap:
          name: logstash-config
      - name: pipeline
        configMap:
          name: logstash-pipeline
      - name: patterns
        configMap:
          name: logstash-patterns
      - name: certs
        secret:
          secretName: elasticsearch-certs
---
# Logstash Service
apiVersion: v1
kind: Service
metadata:
  name: logstash
  namespace: logging
  labels:
    app: logstash
spec:
  selector:
    app: logstash
  ports:
  - port: 5044
    name: beats
    protocol: TCP
  - port: 9600
    name: http
    protocol: TCP
---
# Logstash Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-config
  namespace: logging
data:
  logstash.yml: |
    http.host: "0.0.0.0"
    path.config: /usr/share/logstash/pipeline
    path.logs: /usr/share/logstash/logs
    
    # Security Configuration
    xpack.monitoring.enabled: true
    xpack.monitoring.elasticsearch.hosts: ["https://elasticsearch:9200"]
    xpack.monitoring.elasticsearch.username: logstash_system
    xpack.monitoring.elasticsearch.password: "${ELASTICSEARCH_PASSWORD}"
    xpack.monitoring.elasticsearch.ssl.certificate_authority: /usr/share/logstash/config/certs/ca.crt
    
    # Pipeline Configuration
    pipeline.workers: 4
    pipeline.batch.size: 1000
    pipeline.batch.delay: 50
    
    # Queue Configuration for Reliability
    queue.type: persisted
    queue.max_bytes: 2gb
    queue.checkpoint.writes: 1024
---
# Logstash Pipeline Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-pipeline
  namespace: logging
data:
  logstash.conf: |
    input {
      beats {
        port => 5044
        ssl => true
        ssl_certificate => "/usr/share/logstash/config/certs/logstash.crt"
        ssl_key => "/usr/share/logstash/config/certs/logstash.key"
        ssl_certificate_authorities => ["/usr/share/logstash/config/certs/ca.crt"]
      }
      
      # Kubernetes logs
      http {
        port => 8080
        codec => json
        additional_codecs => {
          "application/json" => "json"
        }
      }
      
      # Syslog input for infrastructure logs
      syslog {
        port => 5514
        codec => cef
      }
    }
    
    filter {
      # Add timestamp
      if ![timestamp] {
        mutate {
          add_field => { "timestamp" => "%{@timestamp}" }
        }
      }
      
      # Parse Kubernetes logs
      if [kubernetes] {
        mutate {
          add_field => { "log_type" => "kubernetes" }
        }
        
        # Extract namespace and pod information
        if [kubernetes][namespace_name] {
          mutate {
            add_field => { "k8s_namespace" => "%{[kubernetes][namespace_name]}" }
          }
        }
        
        if [kubernetes][pod_name] {
          mutate {
            add_field => { "k8s_pod" => "%{[kubernetes][pod_name]}" }
          }
        }
      }
      
      # Parse application logs
      if [fields][app] == "fluxora-api" {
        grok {
          match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{DATA:logger} - %{GREEDYDATA:log_message}" }
        }
        
        mutate {
          add_field => { "log_type" => "application" }
          add_field => { "service" => "fluxora-api" }
        }
        
        # Parse JSON logs if applicable
        if [log_message] =~ /^\{.*\}$/ {
          json {
            source => "log_message"
            target => "parsed_json"
          }
        }
      }
      
      # Security event parsing
      if [tags] and "security" in [tags] {
        mutate {
          add_field => { "log_type" => "security" }
          add_field => { "compliance_relevant" => "true" }
        }
        
        # Parse security events
        grok {
          match => { "message" => "%{WORD:event_type} %{WORD:action} from %{IP:source_ip} to %{IP:dest_ip}:%{INT:dest_port}" }
        }
      }
      
      # Compliance log parsing
      if [tags] and ("pci-dss" in [tags] or "gdpr" in [tags] or "soc2" in [tags]) {
        mutate {
          add_field => { "compliance_log" => "true" }
        }
        
        # Add compliance framework tags
        if "pci-dss" in [tags] {
          mutate { add_field => { "compliance_framework" => "pci-dss" } }
        }
        if "gdpr" in [tags] {
          mutate { add_field => { "compliance_framework" => "gdpr" } }
        }
        if "soc2" in [tags] {
          mutate { add_field => { "compliance_framework" => "soc2" } }
        }
      }
      
      # Audit log parsing
      if [log_type] == "audit" {
        mutate {
          add_field => { "audit_log" => "true" }
          add_field => { "retention_period" => "2555" }  # 7 years in days
        }
        
        # Parse audit events
        grok {
          match => { "message" => "%{TIMESTAMP_ISO8601:audit_timestamp} %{WORD:audit_action} by %{WORD:user} on %{WORD:resource}" }
        }
      }
      
      # Add GeoIP information for security analysis
      if [source_ip] {
        geoip {
          source => "source_ip"
          target => "geoip"
        }
      }
      
      # Anonymize PII for GDPR compliance
      if [compliance_framework] == "gdpr" {
        mutate {
          gsub => [
            "message", "(?i)email:\s*[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}", "email: [REDACTED]",
            "message", "(?i)phone:\s*[\+]?[1-9]?[0-9]{7,15}", "phone: [REDACTED]",
            "message", "(?i)ssn:\s*\d{3}-?\d{2}-?\d{4}", "ssn: [REDACTED]"
          ]
        }
      }
      
      # Add data classification
      if [compliance_log] == "true" or [audit_log] == "true" {
        mutate {
          add_field => { "data_classification" => "restricted" }
        }
      } else if [log_type] == "security" {
        mutate {
          add_field => { "data_classification" => "confidential" }
        }
      } else {
        mutate {
          add_field => { "data_classification" => "internal" }
        }
      }
    }
    
    output {
      # Main Elasticsearch output
      elasticsearch {
        hosts => ["https://elasticsearch:9200"]
        user => "${ELASTICSEARCH_USERNAME}"
        password => "${ELASTICSEARCH_PASSWORD}"
        ssl => true
        ssl_certificate_verification => true
        cacert => "/usr/share/logstash/config/certs/ca.crt"
        
        # Index strategy based on log type and compliance requirements
        index => "fluxora-%{log_type}-%{+YYYY.MM.dd}"
        
        # Use different indices for compliance logs
        if [compliance_log] == "true" {
          index => "compliance-%{compliance_framework}-%{+YYYY.MM.dd}"
        }
        
        if [audit_log] == "true" {
          index => "audit-logs-%{+YYYY.MM.dd}"
        }
        
        # Document type
        document_type => "_doc"
        
        # Template for index settings
        template_name => "fluxora-logs"
        template_pattern => "fluxora-*"
        template => "/usr/share/logstash/templates/fluxora-template.json"
        template_overwrite => true
      }
      
      # SIEM integration output (if configured)
      if [log_type] == "security" or [compliance_log] == "true" {
        http {
          url => "https://siem.fluxora.com/api/events"
          http_method => "post"
          headers => {
            "Authorization" => "Bearer ${SIEM_API_TOKEN}"
            "Content-Type" => "application/json"
          }
          format => "json"
          ssl_certificate_verification => true
        }
      }
      
      # Debug output (remove in production)
      if [log_level] == "debug" {
        stdout {
          codec => rubydebug
        }
      }
    }
---
# Kibana Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kibana
  namespace: logging
  labels:
    app: kibana
    component: logging
spec:
  replicas: 2
  selector:
    matchLabels:
      app: kibana
  template:
    metadata:
      labels:
        app: kibana
        component: logging
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
      - name: kibana
        image: docker.elastic.co/kibana/kibana:8.11.0
        ports:
        - containerPort: 5601
          name: http
        volumeMounts:
        - name: config
          mountPath: /usr/share/kibana/config/kibana.yml
          subPath: kibana.yml
        - name: certs
          mountPath: /usr/share/kibana/config/certs
          readOnly: true
        env:
        - name: ELASTICSEARCH_HOSTS
          value: "https://elasticsearch:9200"
        - name: ELASTICSEARCH_USERNAME
          value: "kibana_system"
        - name: ELASTICSEARCH_PASSWORD
          valueFrom:
            secretKeyRef:
              name: elasticsearch-credentials
              key: kibana_password
        resources:
          limits:
            cpu: 1000m
            memory: 2Gi
          requests:
            cpu: 500m
            memory: 1Gi
        livenessProbe:
          httpGet:
            path: /api/status
            port: 5601
          initialDelaySeconds: 120
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /api/status
            port: 5601
          initialDelaySeconds: 60
          periodSeconds: 10
      volumes:
      - name: config
        configMap:
          name: kibana-config
      - name: certs
        secret:
          secretName: elasticsearch-certs
---
# Kibana Service
apiVersion: v1
kind: Service
metadata:
  name: kibana
  namespace: logging
  labels:
    app: kibana
spec:
  selector:
    app: kibana
  ports:
  - port: 5601
    name: http
    protocol: TCP
  type: ClusterIP
---
# Kibana Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: kibana-config
  namespace: logging
data:
  kibana.yml: |
    server.name: kibana
    server.host: "0.0.0.0"
    server.port: 5601
    
    # Elasticsearch Configuration
    elasticsearch.hosts: ["https://elasticsearch:9200"]
    elasticsearch.username: "${ELASTICSEARCH_USERNAME}"
    elasticsearch.password: "${ELASTICSEARCH_PASSWORD}"
    elasticsearch.ssl.certificateAuthorities: ["/usr/share/kibana/config/certs/ca.crt"]
    elasticsearch.ssl.verificationMode: certificate
    
    # Security Configuration
    server.ssl.enabled: true
    server.ssl.certificate: /usr/share/kibana/config/certs/kibana.crt
    server.ssl.key: /usr/share/kibana/config/certs/kibana.key
    
    # Kibana Security
    xpack.security.enabled: true
    xpack.security.encryptionKey: "something_at_least_32_characters_long"
    xpack.security.session.idleTimeout: "1h"
    xpack.security.session.lifespan: "8h"
    
    # Monitoring
    xpack.monitoring.ui.container.elasticsearch.enabled: true
    
    # Compliance and Audit
    xpack.security.audit.enabled: true
    xpack.security.audit.appender.type: file
    xpack.security.audit.appender.fileName: /usr/share/kibana/logs/kibana_audit.log
    xpack.security.audit.appender.layout.type: json
    
    # Index Patterns
    kibana.defaultAppId: "discover"
    
    # Data Views (Index Patterns)
    data.search.timeout: 600000
    
    # Reporting
    xpack.reporting.enabled: true
    xpack.reporting.encryptionKey: "something_at_least_32_characters_long"
    
    # Canvas
    xpack.canvas.enabled: true
    
    # Maps
    xpack.maps.enabled: true
    
    # Machine Learning (if licensed)
    xpack.ml.enabled: false
    
    # Alerting
    xpack.alerting.enabled: true
    xpack.actions.enabled: true

