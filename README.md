# Advanced Energy Consumption Forecasting System

[![CI Status](https://img.shields.io/github/actions/workflow/status/abrar2030/Fluxora/ci-cd.yml?branch=main&label=CI&logo=github)](https://github.com/abrar2030/Fluxora/actions)
[![CI Status](https://img.shields.io/github/workflow/status/abrar2030/Fluxora/CI/main?label=CI)](https://github.com/abrar2030/Fluxora/actions)
[![Test Coverage](https://img.shields.io/codecov/c/github/abrar2030/Fluxora/main?label=Coverage)](https://codecov.io/gh/abrar2030/Fluxora)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10](https://img.shields.io/badge/python-3.10-blue.svg)](https://www.python.org/)
[![MLflow](https://img.shields.io/badge/MLflow-Enabled-orange)](https://mlflow.org/)

An end-to-end MLOps solution for industrial-grade energy consumption forecasting, featuring automated retraining, real-time monitoring, and Kubernetes-native deployment.

<div align="center">
  <img src="docs/Fluxora.bmp" alt="An end-to-end MLOps solution for industrial-grade energy consumption forecasting" width="100%">
</div>

> **Note**: This Project is currently under active development. Features and functionalities are being added and improved continuously to enhance user experience.

## Table of Contents
- [Key Features](#-key-features)
- [Feature Implementation Status](#feature-implementation-status)
- [Installation](#-installation)
- [API Endpoints](#-api-endpoints)
- [Monitoring Stack](#-monitoring-stack)
- [Project Structure](#-project-structure)
- [Configuration](#-configuration)
- [Model Versioning](#-model-versioning)
- [Data Validation](#-data-validation)
- [Testing](#testing)
- [CI/CD Pipeline](#cicd-pipeline)
- [Contributing](#-contributing)
- [License](#-license)

## ğŸš€ Key Features

- **Multi-Model Serving**: XGBoost, LSTM, Prophet ensemble predictions  
- **MLOps Infrastructure**:
  - Kubernetes-native deployment with Istio  
  - MLflow Model Registry  
  - Feast Feature Store  
  - Prometheus/Grafana monitoring  
- **Data Quality Assurance**:
  - Great Expectations validations  
  - Temporal coherence checks  
  - Automated data drift detection  
- **Production-Grade API**:
  - JWT Authentication  
  - Rate limiting  
  - Canary deployments  
- **Smart Forecasting**:
  - Probabilistic predictions  
  - SHAP explainability  
  - Counterfactual analysis  

## Feature Implementation Status

| Feature | Status | Description | Planned Release |
|---------|--------|-------------|----------------|
| **Multi-Model Serving** |
| XGBoost Model | âœ… Implemented | Gradient boosting for tabular data | v1.0 |
| LSTM Model | âœ… Implemented | Deep learning for sequential data | v1.0 |
| Prophet Model | âœ… Implemented | Time series decomposition | v1.0 |
| Ensemble Integration | âœ… Implemented | Weighted model combination | v1.0 |
| AutoML Selection | ğŸ“… Planned | Automatic model selection | v2.0 |
| **MLOps Infrastructure** |
| Kubernetes Deployment | âœ… Implemented | K8s manifests and Helm charts | v1.0 |
| Istio Service Mesh | âœ… Implemented | Traffic management and observability | v1.0 |
| MLflow Registry | âœ… Implemented | Model versioning and tracking | v1.0 |
| Feast Feature Store | ğŸ”„ In Progress | Feature management and serving | v1.1 |
| CI/CD Pipeline | âœ… Implemented | Automated testing and deployment | v1.0 |
| **Data Quality Assurance** |
| Great Expectations | âœ… Implemented | Data validation framework | v1.0 |
| Temporal Checks | âœ… Implemented | Time series specific validations | v1.0 |
| Drift Detection | ğŸ”„ In Progress | Automated data drift monitoring | v1.1 |
| Anomaly Detection | ğŸ“… Planned | Identify outliers in input data | v1.2 |
| **Production-Grade API** |
| JWT Authentication | âœ… Implemented | Secure API access | v1.0 |
| Rate Limiting | âœ… Implemented | Prevent API abuse | v1.0 |
| Canary Deployments | ğŸ”„ In Progress | Gradual rollout of new versions | v1.1 |
| API Documentation | âœ… Implemented | OpenAPI/Swagger docs | v1.0 |
| **Smart Forecasting** |
| Probabilistic Predictions | âœ… Implemented | Confidence intervals for forecasts | v1.0 |
| SHAP Explainability | âœ… Implemented | Feature importance analysis | v1.0 |
| Counterfactual Analysis | ğŸ”„ In Progress | What-if scenario modeling | v1.1 |
| Hierarchical Forecasting | ğŸ“… Planned | Multi-level time series forecasting | v1.2 |

**Legend:**
- âœ… Implemented: Feature is complete and available
- ğŸ”„ In Progress: Feature is currently being developed
- ğŸ“… Planned: Feature is planned for future release

## ğŸ“¦ Installation

### Prerequisites
- Kubernetes cluster (minikube supported)  
- Python 3.10+  
- Docker 20.10+  
- Apache Spark 3.3+  

```bash
# Clone repository
git clone https://github.com/abrar2030/Fluxora.git
cd Fluxora

# Initialize environment
make bootstrap && dvc pull
```

## ğŸ› ï¸ Usage

### Data Pipeline
```bash
# Run complete data processing
make data_pipeline
```

### Model Training
```bash
# Train all models
make train

# Hyperparameter tuning
make tune
```

### Deployment
```bash
# Deploy to Kubernetes
make deploy_prod

# Monitor deployment
kubectl get pods -n energy-forecast
```

## ğŸŒ API Endpoints

| Endpoint       | Method | Description                     |
|----------------|--------|---------------------------------|
| `/predict`     | POST   | Get energy forecasts            |
| `/monitor`     | GET    | Model performance metrics       |
| `/retrain`     | POST   | Trigger model retraining        |
| `/health`      | GET    | System health status            |

### Sample Prediction Request:
```bash
curl -X POST http://api/predict \
  -H "Content-Type: application/json" \
  -H "X-API-Key: $SECRET_KEY" \
  -d '{
    "timestamp": "2023-08-15T14:00:00",
    "meter_id": "MT_001",
    "historical_load": [0.45, 0.48, 0.52]
  }'
```

### Sample Response:
```json
{
  "prediction": 0.49,
  "confidence_interval": [0.46, 0.53],
  "model_version": "prod-v1.2.0",
  "shap_values": {
    "temperature": 0.12,
    "hour_of_day": -0.08
  }
}
```

## ğŸ“Š Monitoring Stack

Access monitoring tools:
```bash
# Grafana
open http://localhost:3000

# Prometheus
open http://localhost:9090

# MLflow UI
mlflow ui --port 5000
```

## ğŸ§© Project Structure
```
energy-forecasting/
â”œâ”€â”€ deployments/          # Kubernetes manifests
â”œâ”€â”€ feature_repo/         # Feast feature definitions
â”œâ”€â”€ mlflow/               # Experiment tracking
â”œâ”€â”€ monitoring/           # Grafana/Prometheus configs
â”œâ”€â”€ pipelines/            # Prefect workflows
â””â”€â”€ src/
    â”œâ”€â”€ api/              # FastAPI service
    â”œâ”€â”€ data/             # ETL pipelines
    â”œâ”€â”€ models/           # Model architectures
    â”œâ”€â”€ monitoring/       # Data drift detection
    â””â”€â”€ visualization/    # Plotting utilities
```

## âš™ï¸ Configuration

Modify `config/config.yaml`:
```yaml
model:
  production_threshold: 0.85  # Minimum accuracy for deployment
  drift:
    threshold: 0.15           # Data drift alert level

feature_store:
  offline_store: s3://energy-data/features
  online_store: redis://redis:6379

api:
  rate_limit: "100/minute"
```

## ğŸ¤– Model Versioning
```python
from src.models.model_versioning import promote_model

# Promote best performing model
promote_model(
    run_id="a1b2c3d4", 
    validation_metric="mae",
    threshold=0.45
)
```

## ğŸ” Data Validation
```python
from src.data.data_validator import validate_energy_data

# Validate incoming data
validation_report = validate_energy_data(
    df, 
    expectation_suite="energy_suite"
)

if not validation_report.success:
    handle_invalid_data(validation_report)
```

## Testing

The project includes comprehensive testing to ensure reliability and accuracy:

### Unit Testing
- Model component tests
- Data processing pipeline tests
- API endpoint tests

### Integration Testing
- End-to-end pipeline tests
- Model training workflow tests
- Feature store integration tests

### Performance Testing
- Model inference latency tests
- API throughput tests
- Scalability tests

To run tests:
```bash
# Run all tests
make test

# Run specific test suite
make test_models
make test_api
make test_pipelines

# Run with coverage
make test_coverage
```

## CI/CD Pipeline

Fluxora uses GitHub Actions for continuous integration and deployment:

### Continuous Integration
- Automated testing on each pull request and push to main
- Code quality checks with pylint and black
- Test coverage reporting with pytest-cov
- Security scanning for vulnerabilities

### Continuous Deployment
- Automated model training and evaluation
- Model registry updates
- Kubernetes deployment with canary releases
- Monitoring dashboard updates

Current CI/CD Status:
- Build: ![Build Status](https://img.shields.io/github/workflow/status/abrar2030/Fluxora/CI/main?label=build)
- Test Coverage: ![Coverage](https://img.shields.io/codecov/c/github/abrar2030/Fluxora/main?label=coverage)
- Model Quality: ![Model Quality](https://img.shields.io/badge/model%20quality-0.92%20MAE-brightgreen)

## ğŸ¤ Contributing

We welcome contributions to improve Fluxora! Here's how you can contribute:

1. **Fork the repository**
   - Create your own copy of the project to work on

2. **Create a feature branch**
   - `git checkout -b feature/amazing-feature`
   - Use descriptive branch names that reflect the changes

3. **Make your changes**
   - Follow the coding standards and guidelines
   - Write clean, maintainable, and tested code
   - Update documentation as needed

4. **Commit your changes**
   - `git commit -m 'Add some amazing feature'`
   - Use clear and descriptive commit messages
   - Reference issue numbers when applicable

5. **Push to branch**
   - `git push origin feature/amazing-feature`

6. **Open Pull Request**
   - Provide a clear description of the changes
   - Link to any relevant issues
   - Respond to review comments and make necessary adjustments

### Development Guidelines

- Follow PEP 8 style guide for Python code
- Write unit tests for new features
- Update documentation for any changes
- Ensure all tests pass before submitting a pull request
- Keep pull requests focused on a single feature or fix

## ğŸ“œ License

Distributed under the MIT License. See [LICENSE](LICENSE) for more information.